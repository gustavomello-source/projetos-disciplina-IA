# -*- coding: utf-8 -*-
"""Projeto2_Titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h7v1fT_aUIpg3nmB74tF67xYrVg8aOl7

Nome do aluno: Gustavo José da Silveira Mello

# **Projeto 2: Titanic**

##**Base de dados**: https://www.kaggle.com/datasets/yasserh/titanic-dataset

- Aplicar a separação do conjunto treino (com 70%) e teste (30%);
- Classicadores: Poderá ser utilizado os classicadores Decision Tree, Randon
Forest, KNN e Redes Neurais (biliotecas scikit-learn e Keras).

###Entrada de dados
"""

#from google.colab import files
#uploaded = files.upload()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('Titanic-Dataset.csv')

type(data)

"""####Criando tabelas
- Acurácias gerais
- Médias dos 10 folds
- Conjunto Teste
"""

#uploaded2 = files.upload()
tabelaAcc = pd.read_csv('accsTitanic.csv')

tabelaMedias = pd.read_csv('medias.csv')

tabelaTestes = pd.read_csv('conjuntoTeste.csv')

tabelaTreino = pd.read_csv('conjuntoTreino.csv')

type(tabelaAcc)

tabelaAcc

tabelaMedias

tabelaAcc['Com Cabin'] = tabelaAcc['Com Cabin'].astype(bool)

colunasFloat = ['Decision Tree', 'Random Forest', 'KNN', 'Redes Neurais 1 camada', 'Redes Neurais 2 camadas', 'Redes Neurais 3 camadas']
tabelaAcc[colunasFloat] = tabelaAcc[colunasFloat].astype(float)

tabelaAcc.loc[0, 'Com Cabin'] = True
tabelaAcc.loc[1, 'Com Cabin'] = False
tabelaAcc.loc[2, 'Com Cabin'] = True
tabelaAcc.loc[3, 'Com Cabin'] = False
tabelaAcc.loc[4, 'Com Cabin'] = True
tabelaAcc.loc[5, 'Com Cabin'] = False
tabelaAcc.loc[6, 'Com Cabin'] = True
tabelaAcc.loc[7, 'Com Cabin'] = False

"""### Informações gerais:"""

data.tail(10)

data.info()

data.describe()

data['Survived'].value_counts()

#data.isna().value_counts()
data.isna().sum()

"""### Tratamento de Dados
- Transformação de dados categóricos (binarização)
- Tabelas *'Name'*, *'PassengerId'* e *'Ticket'* não é necessária
- Substituição de NaNs de '*Age*' por mediana
- Substituição de NaNs de '*Cabin*' por valores simulados
- X2 - Não possue a coluna '*Cabin*'
- y2 - Obtem os valores da classe e treina com X2
"""

data['Survived']

from sklearn.preprocessing import LabelEncoder
Le = LabelEncoder()

data['Sex'] = Le.fit_transform(data['Sex'])
data = pd.get_dummies(data=data, columns=['Embarked']) # binarização da categoria 'Embarked'

import statistics  as sts

"""Substituindo NaNs de '*Age*' por valores de mediana"""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.NaN, strategy='median')

data['Age'] = imputer.fit_transform(data['Age'].values.reshape(-1,1))[:,0]

imputer.statistics_
#A mediana é 28, portanto, haverá 177 pessoas com 28 anos a mais

"""Balanceando (e substituindo NaNs) da coluna '*Cabin*'"""

data.isna().sum()

"""Criação da base de teste e treino sem a coluna '*Cabin*' (base que não precisará de tratamento desses dados)"""

y2 = data['Survived']
X2 = data.drop(['Survived', 'Name', 'PassengerId', 'Ticket', 'Cabin'], axis=1).values

"""Tratamento de '*Cabin*' (cada cabine inicia com uma letra e números, ou seja, é possível fazer binarização da letra, separando-a e depois um dado numérico para a cabine)
* 1 - Separar *'Cabin'* em: *'Cabin_Letter'* e *'Cabin'*
* 2 - Utilizar SimpleImputer para preencher *'Cabin_Letter'* restantes
* 3 - Binarizar *'Cabin_Letter'*
* 4 - Utilizar *drop* em *'Cabin'*
"""

data['Cabin']

data['Cabin_Letter'] = data['Cabin'].str[0]

imputer = SimpleImputer(strategy='most_frequent')

data['Cabin_Letter'] = imputer.fit_transform(data[['Cabin_Letter']])

"""Binarizando '*Cabin_Letter*'"""

data = pd.get_dummies(data=data, columns=['Cabin_Letter']) # binarização da categoria 'Cabin_Letter'

data.isna().sum()

data

"""### Treinamento

Divisão da base de dados em treino e teste
* y - Obtem os valores da classe.
* X - Obtem os dados de treinamento (previsores).
"""

y = data['Survived']
X = data.drop(['Survived', 'Name', 'PassengerId', 'Ticket', 'Cabin'], axis=1).values

from sklearn import model_selection

#treinamento
X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=10)

#treinamento sem 'Cabin'
X2_train, X2_test, y2_train, y2_test = model_selection.train_test_split(X2, y2, test_size=0.3, random_state=10)

"""Balanceamento da classe *'Survived'*"""

from imblearn.over_sampling import SMOTE

sm = SMOTE()
x_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)

x2_train_oversampled, y2_train_oversampled = sm.fit_resample(X2_train, y2_train)

print(x_train_oversampled.shape)
print(X_train.shape)

print(x2_train_oversampled.shape)
print(X2_train.shape)

"""## SKLEARN

### Decision Tree

#### Decision Tree com '*Cabin*'
"""

from sklearn import metrics
from sklearn.model_selection import train_test_split

from sklearn import tree
clf = tree.DecisionTreeClassifier(criterion = 'entropy')
clf = clf.fit(x_train_oversampled, y_train_oversampled)

# Predições
y_pred = clf.predict(X_test)

y_proba = clf.predict_proba(X_test)

#y_proba

#tree.plot_tree(clf)

acc = metrics.accuracy_score(y_test, y_pred, normalize=True)
acc

tabelaAcc.loc[0, 'Decision Tree'] = acc

"""#### Decision Tree Sem '*Cabin*'"""

from sklearn import metrics
from sklearn.model_selection import train_test_split

from sklearn import tree
clf2 = tree.DecisionTreeClassifier(criterion = 'entropy')
clf2 = clf2.fit(x2_train_oversampled, y2_train_oversampled)

# Predições
y2_pred = clf2.predict(X2_test)

y2_proba = clf2.predict_proba(X2_test)

#y2_proba

#tree.plot_tree(clf2)

acc2 = metrics.accuracy_score(y2_test, y2_pred)
acc2

tabelaAcc.loc[1, 'Decision Tree'] = acc2

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier

"""Usando Cabin (X e y)"""

forest = RandomForestClassifier(random_state=42)
#==
forest.fit(x_train_oversampled, y_train_oversampled)
#==
#Score
#==
forest_score = forest.score(x_train_oversampled, y_train_oversampled)
forest_test = forest.score(X_test, y_test, sample_weight=None)
#==
#testing model
#==
y_pred = forest.predict(X_test)
#==
#evaluation
#==
#cm = confusion_matrix(y_test,y_pred)
print('Training Score',forest_score)
print('\nTesting Score',forest_test)
#print(cm)

tabelaAcc.loc[0, 'Random Forest'] = forest_test

"""Sem Cabin (X2 e y2)"""

forest2 = RandomForestClassifier(random_state=42)

forest2.fit(x2_train_oversampled, y2_train_oversampled)

#Score

forest2_score = forest2.score(x2_train_oversampled, y2_train_oversampled)
forest2_test = forest2.score(X2_test, y2_test, sample_weight=None)

#testing model

y2_pred = forest2.predict(X2_test)

#evaluation

#cm = confusion_matrix(y_test,y_pred)
print('Training Score',forest2_score)
print('Testing Score \n',forest2_test)
#print(cm)

tabelaAcc.loc[1, 'Random Forest'] = forest2_test

"""### KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics

"""#### Com Cabin"""

k = 5
knn = KNeighborsClassifier(n_neighbors=k,metric = 'euclidean')
knn.fit(x_train_oversampled, y_train_oversampled)
y_pred = knn.predict(x_train_oversampled)
acc_KNN_0 = metrics.accuracy_score(y_train_oversampled, y_pred, normalize = True)

y_proba = knn.predict_proba(X_test)

tabelaAcc.loc[0, 'KNN'] = acc_KNN_0

"""#### Sem Cabin"""

k = 5
knn = KNeighborsClassifier(n_neighbors=k,metric = 'euclidean')
knn.fit(x2_train_oversampled, y2_train_oversampled)
y2_pred = knn.predict(X2_test)
acc_KNN_1 = metrics.accuracy_score(y2_test, y2_pred, normalize = True)

y2_proba = knn.predict_proba(X2_test)

tabelaAcc.loc[1, 'KNN'] = acc_KNN_1

"""### Redes Neurais"""

from sklearn.neural_network import MLPClassifier

"""####Classificadores"""

rna_1 = MLPClassifier(hidden_layer_sizes=(50), activation='relu', solver='sgd', max_iter =1000,
                              tol=0.0001, random_state = 3, verbose = True)
rna_2 = MLPClassifier(hidden_layer_sizes=(50, 100), activation='relu', solver='sgd', max_iter =1000,
                              tol=0.0001, random_state = 3, verbose = True)
rna_3 = MLPClassifier(hidden_layer_sizes=(50, 100, 50), activation='relu', solver='sgd', max_iter =1000,
                              tol=0.0001, random_state = 3, verbose = True)

"""####Com Cabin"""

rna_1.fit(x_train_oversampled, y_train_oversampled)

rna_2.fit(x_train_oversampled, y_train_oversampled)

rna_3.fit(x_train_oversampled, y_train_oversampled)

previsoes_1 = rna_1.predict(X_test)

previsoes_2 = rna_2.predict(X_test)

previsoes_3 = rna_3.predict(X_test)

"""####Sem Cabin"""

rna_1.fit(x2_train_oversampled, y2_train_oversampled)

rna_2.fit(x2_train_oversampled, y2_train_oversampled)

rna_3.fit(x2_train_oversampled, y2_train_oversampled)

previsoes_4 = rna_1.predict(X2_test)

previsoes_5 = rna_2.predict(X2_test)

previsoes_6 = rna_3.predict(X2_test)

"""####Resultados"""

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""Com Cabin"""

acc_rna_1 = (accuracy_score(y_test, previsoes_1) * 100.0)
acc_rna_2 = (accuracy_score(y_test, previsoes_2) * 100.0)
acc_rna_3 = (accuracy_score(y_test, previsoes_3) * 100.0)

print("Acurácias com Cabin:")
print("\nUma Camada: %.2f" %acc_rna_1)
print("\nDuas Camadas: %.2f" %acc_rna_2)
print("\nTrês Camadas: %.2f" %acc_rna_3)

tabelaAcc.loc[0, 'Redes Neurais 1 camada'] = acc_rna_1
tabelaAcc.loc[0, 'Redes Neurais 2 camadas'] = acc_rna_2
tabelaAcc.loc[0, 'Redes Neurais 3 camadas'] = acc_rna_3

"""Sem Cabin"""

acc_rna_4 = (accuracy_score(y_test, previsoes_4) * 100.0)
acc_rna_5 = (accuracy_score(y_test, previsoes_5) * 100.0)
acc_rna_6 = (accuracy_score(y_test, previsoes_6) * 100.0)

print("Acurácias sem Cabin:")
print("\nUma Camada: %.2f" %acc_rna_4)
print("\nDuas Camadas: %.2f" %acc_rna_5)
print("\nTrês Camadas: %.2f" %acc_rna_6)

tabelaAcc.loc[1, 'Redes Neurais 1 camada'] = acc_rna_4
tabelaAcc.loc[1, 'Redes Neurais 2 camadas'] = acc_rna_5
tabelaAcc.loc[1, 'Redes Neurais 3 camadas'] = acc_rna_6

"""##Keras"""

import tensorflow as tf

"""###Com Cabin"""

rna_keras_model = tf.keras.Sequential([
tf.keras.layers.Dense(units=1,input_shape=[18-1])])

# after you create your model it's
# always a good habit to print out it's summary
rna_keras_model.summary()

rna_keras_model = tf.keras.Sequential([

	tf.keras.layers.Dense(units=100, activation='relu',
						input_shape=[18-1]),
	tf.keras.layers.Dense(units=1)
])
rna_keras_model.summary()

rna_keras_model.compile(optimizer='adam',

			# MAE error is good for
			# numerical predictions
			loss='mae',
             metrics=[tf.keras.metrics.BinaryAccuracy()])

losses = rna_keras_model.fit(x_train_oversampled, y_train_oversampled,

				validation_data=(X_test, y_test),

				# it will use 'batch_size' number
				# of examples per example
				batch_size=256,
				epochs=500, # total epoch

				)

rna_keras_prediction = rna_keras_model.predict(X_test)

loss_df = pd.DataFrame(losses.history)

# history stores the loss/val
# loss in each epoch

# loss_df is a dataframe which
# contains the losses so we can
# plot it to visualize our model training
loss_df.loc[:,['binary_accuracy','val_binary_accuracy']].plot()

binary_predictions = (rna_keras_prediction > 0.5).astype(int)

keras_accuracy_ = accuracy_score(y_test, binary_predictions)
keras_accuracy_

tabelaAcc.loc[2, 'Redes Neurais 1 camada'] = keras_accuracy_

"""###Sem Cabin"""

rna_keras_model_1 = tf.keras.Sequential([
tf.keras.layers.Dense(units=1,input_shape=[10-1])])

# after you create your model it's
# always a good habit to print out it's summary
rna_keras_model_1.summary()

rna_keras_model_1 = tf.keras.Sequential([

	tf.keras.layers.Dense(units=100, activation='relu',
						input_shape=[10-1]),
	tf.keras.layers.Dense(units=1)
])
rna_keras_model_1.summary()

rna_keras_model_1.compile(optimizer='adam',

			# MAE error is good for
			# numerical predictions
			loss='mae',
             metrics=[tf.keras.metrics.BinaryAccuracy()])

losses_1 = rna_keras_model_1.fit(x2_train_oversampled, y2_train_oversampled,

				validation_data=(X2_test, y2_test),

				# it will use 'batch_size' number
				# of examples per example
				batch_size=256,
				epochs=500, # total epoch

				)

rna_keras_prediction_1 = rna_keras_model_1.predict(X2_test)

loss_1_df = pd.DataFrame(losses.history)

# history stores the loss/val
# loss in each epoch

# loss_df is a dataframe which
# contains the losses so we can
# plot it to visualize our model training
loss_1_df.loc[:,['binary_accuracy','val_binary_accuracy']].plot()

binary_predictions = (rna_keras_prediction_1 > 0.5).astype(int)

keras_accuracy_1 = accuracy_score(y_test, binary_predictions)
keras_accuracy_1

tabelaAcc.loc[3, 'Redes Neurais 1 camada'] = keras_accuracy_1

"""## AJUSTE DOS HIPERPARÂMETROS"""

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

"""#### RandomForest Classifier"""

forest = RandomForestClassifier()
# param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],
#               'max_features':['sqrt','log2'],
#               'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 100, 200, 300]} EXEMPLO
forest_param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],
              'max_features':['sqrt','log2'],
              'n_estimators': [10, 20, 30, 60, 100]}

"""#### Decision Tree Classifier"""

decisionTree = tree.DecisionTreeClassifier()

decisionTree_param_grid = {"splitter":["best","random"],
            "max_depth" : [1,3,5,9,12],
           "min_samples_leaf":[1,3, 6, 9],
           "min_weight_fraction_leaf":[0.1,0.3, 0.5],
           "max_features":["log2","sqrt"],
           "max_leaf_nodes":[10,30,60,90] }

"""####KNN Classifier"""

knn = KNeighborsClassifier()

knn_param_grid = {
    'n_neighbors': [3, 5, 7, 9, 13],
    'weights': ['uniform', 'distance'],
    'algorithm': ['ball_tree', 'kd_tree'],
    'leaf_size': [10, 20, 30],
    'p': [1, 2],
    'metric': ['euclidean', 'manhattan']
    }

"""#### Redes Neurais SKLEARN Classifier"""

rna_param_grid = {'hidden_layer_sizes': [(25,), (25, 50), (25, 50, 25)],
                  'activation': ['relu', 'logistic'],
                  'solver': ['sgd', 'adam']
                  #'alpha': [0.0001, 0.001, 0.01],
                  #'learning_rate': ['constant', 'adaptive']
                  }

"""#### GridSearch

#####Random Forest
"""

forest_g_search = GridSearchCV(estimator = forest, param_grid = forest_param_grid,
                        cv = 10, return_train_score=True) #RANDOM FOREST COM CABIN
forest_g2_search = GridSearchCV(estimator = forest, param_grid = forest_param_grid,
                        cv = 10, return_train_score=True) # RANDOM FOREST SEM CABIN

forest_refit_g_search = GridSearchCV(estimator = forest, param_grid = forest_param_grid,
                        refit=True, scoring='accuracy', cv = 10)#refit com cabin
forest_refit_g2_search = GridSearchCV(estimator = forest, param_grid = forest_param_grid,
                        refit=True, scoring='accuracy', cv = 10)#refit sem cabin

forest_g_search.fit(x_train_oversampled, y_train_oversampled);
print(f'\nMelhores Parâmetros: Random Forest com Cabin: ', forest_g_search.best_params_)
forest_g2_search.fit(x2_train_oversampled, y2_train_oversampled);
print(f'\nMelhores Parâmetros: Random Forest sem Cabin: ',forest_g2_search.best_params_)

print(f'\nMelhor Acurácia: Random Forest com Cabin: ', forest_g_search.best_score_)
print(f'\nMelhor Acurácia: Random Forest sem Cabin: ', forest_g2_search.best_score_)

tabelaAcc.loc[4, 'Random Forest'] = forest_g_search.best_score_
tabelaAcc.loc[5, 'Random Forest'] = forest_g2_search.best_score_

"""Conjunto Treino"""

forest_refit_g_search.fit(x_train_oversampled, y_train_oversampled);

forest_refit_g2_search.fit(x2_train_oversampled, y2_train_oversampled);

forest_train_g_results =  pd.DataFrame(forest_refit_g_search.cv_results_)
forest_train_g2_results =  pd.DataFrame(forest_refit_g2_search.cv_results_)

forest_train_g_results.loc[forest_refit_g_search.best_index_,'mean_test_score']

forest_train_g2_results.loc[forest_refit_g2_search.best_index_,'mean_test_score']

forest_train_g_search_model = forest_refit_g_search.best_estimator_
media_g_forest_treino = forest_train_g_search_model.score(x_train_oversampled,y_train_oversampled)
media_g_forest_treino

forest_train_g2_search_model = forest_refit_g2_search.best_estimator_
media_g2_forest_treino = forest_train_g2_search_model.score(x2_train_oversampled,y2_train_oversampled)
media_g2_forest_treino

tabelaTreino.loc[0, 'Random Forest 1'] = media_g_forest_treino
tabelaTreino.loc[0, 'Random Forest 2'] = media_g2_forest_treino

"""Média das Acurácias"""

forest_g_results =  pd.DataFrame(forest_g_search.cv_results_)
forest_g2_results = pd.DataFrame(forest_g2_search.cv_results_)

media_forest_g = forest_g_results.loc[forest_g_search.best_index_,'mean_test_score']
media_forest_g

media_forest_g2 = forest_g2_results.loc[forest_g2_search.best_index_,'mean_test_score']
media_forest_g2

"""#####Decision Tree"""

rtree_g_search = GridSearchCV(estimator = decisionTree, param_grid = decisionTree_param_grid,
                        cv = 10, return_train_score=True) #DECISION TREE COM CABIN
rtree_g2_search = GridSearchCV(estimator = decisionTree, param_grid = decisionTree_param_grid,
                        cv = 10, return_train_score=True) # DECISION TREE SEM CABIN

rtree_refit_g_search = GridSearchCV(estimator = decisionTree, param_grid = decisionTree_param_grid,
                        refit=True, scoring='accuracy', cv = 10)#refit com cabin
rtree_refit_g2_search = GridSearchCV(estimator = decisionTree, param_grid = decisionTree_param_grid,
                        refit=True, scoring='accuracy', cv = 10)#refit sem cabin

rtree_g_search.fit(x_train_oversampled, y_train_oversampled);
print(f'\nMelhores Parâmetros: Decision Tree com Cabin: ', rtree_g_search.best_params_)
rtree_g2_search.fit(x2_train_oversampled, y2_train_oversampled);
print(f'\nMelhores Parâmetros: Decision Tree sem Cabin: ',rtree_g2_search.best_params_)

print(f'\nMelhor Acurácia: Decision Tree com Cabin: ', rtree_g_search.best_score_)
print(f'\nMelhor Acurácia: Decision Tree sem Cabin: ', rtree_g2_search.best_score_)

tabelaAcc.loc[4, 'Decision Tree'] = rtree_g_search.best_score_
tabelaAcc.loc[5, 'Decision Tree'] = rtree_g2_search.best_score_

"""Conjunto Treino"""

rtree_refit_g_search.fit(x_train_oversampled, y_train_oversampled);

rtree_refit_g2_search.fit(x2_train_oversampled, y2_train_oversampled);

rtree_train_g_results =  pd.DataFrame(rtree_refit_g_search.cv_results_)
rtree_train_g2_results =  pd.DataFrame(rtree_refit_g2_search.cv_results_)

rtree_train_g_results.loc[rtree_refit_g_search.best_index_,'mean_test_score']

rtree_train_g2_results.loc[rtree_refit_g2_search.best_index_,'mean_test_score']

rtree_train_g_search_model = rtree_refit_g_search.best_estimator_
media_g_rtree_treino = rtree_train_g_search_model.score(x_train_oversampled,y_train_oversampled)
media_g_rtree_treino

rtree_train_g2_search_model = rtree_refit_g2_search.best_estimator_
media_g2_rtree_treino = rtree_train_g2_search_model.score(x2_train_oversampled,y2_train_oversampled)
media_g2_rtree_treino

tabelaTreino.loc[0, 'Decision Tree 1'] = media_g_rtree_treino
tabelaTreino.loc[0, 'Decision Tree 2'] = media_g2_rtree_treino

"""Média das Acurácias"""

rtree_g_results =  pd.DataFrame(rtree_g_search.cv_results_)
rtree_g2_results = pd.DataFrame(rtree_g2_search.cv_results_)

media_rtree_g = rtree_g_results.loc[rtree_g_search.best_index_,'mean_test_score']

media_rtree_g2 = rtree_g2_results.loc[rtree_g2_search.best_index_,'mean_test_score']

"""#####KNN"""

knn_g_search = GridSearchCV(estimator = knn, param_grid = knn_param_grid,
                        cv = 10, return_train_score=True)
knn_g2_search = GridSearchCV(estimator = knn, param_grid = knn_param_grid,
                        cv = 10, return_train_score=True)

knn_refit_g_search = GridSearchCV(estimator = knn, param_grid = knn_param_grid,
                        refit=True, scoring='accuracy', cv = 10)#refit com cabin
knn_refit_g2_search = GridSearchCV(estimator = knn, param_grid = knn_param_grid,
                        refit=True, scoring='accuracy', cv = 10)#refit sem cabin

knn_g_search.fit(x_train_oversampled, y_train_oversampled);
print(f'\nMelhores Parâmetros: KNN com Cabin: ', knn_g_search.best_params_)
knn_g2_search.fit(x2_train_oversampled, y2_train_oversampled);
print(f'\nMelhores Parâmetros: KNN sem Cabin: ',knn_g2_search.best_params_)

print(f'\nMelhor Acurácia: Decision Tree com Cabin: ', knn_g_search.best_score_)
print(f'\nMelhor Acurácia: Decision Tree sem Cabin: ', knn_g2_search.best_score_)

tabelaAcc.loc[4, 'KNN'] = knn_g_search.best_score_
tabelaAcc.loc[5, 'KNN'] = knn_g2_search.best_score_

"""Conjunto Treino"""

knn_refit_g_search.fit(x_train_oversampled, y_train_oversampled);
knn_refit_g2_search.fit(x2_train_oversampled, y2_train_oversampled);

knn_train_g_results =  pd.DataFrame(knn_refit_g_search.cv_results_)
knn_train_g2_results =  pd.DataFrame(knn_refit_g2_search.cv_results_)

knn_train_g_results.loc[knn_refit_g_search.best_index_,'mean_test_score']

knn_train_g2_results.loc[knn_refit_g2_search.best_index_,'mean_test_score']

knn_train_g_search_model = knn_refit_g_search.best_estimator_
media_g_knn_treino = knn_train_g_search_model.score(x_train_oversampled,y_train_oversampled)
media_g_knn_treino

knn_train_g2_search_model = knn_refit_g2_search.best_estimator_
media_g2_knn_treino = knn_train_g2_search_model.score(x2_train_oversampled,y2_train_oversampled)
media_g2_knn_treino

tabelaTreino.loc[0, 'KNN 1'] = media_g_knn_treino
tabelaTreino.loc[0, 'KNN 2'] = media_g2_knn_treino

"""Média das Acurácias"""

knn_g_results =  pd.DataFrame(knn_g_search.cv_results_)
knn_g2_results = pd.DataFrame(knn_g2_search.cv_results_)

media_knn_g = knn_g_results.loc[knn_g_search.best_index_,'mean_test_score']

media_knn_g2 = knn_g2_results.loc[knn_g2_search.best_index_,'mean_test_score']

"""#####RNA"""

from sklearn.neural_network import MLPClassifier

mlp_g = MLPClassifier(max_iter=2000)

rna_g_search = GridSearchCV(estimator = mlp_g, param_grid = rna_param_grid,
                        cv = 10, return_train_score=True)
rna_g2_search = GridSearchCV(estimator = mlp_g, param_grid = rna_param_grid,
                        cv = 10, return_train_score=True)

rna_refit_g_search = GridSearchCV(estimator = mlp_g, param_grid = rna_param_grid,
                        refit=True, scoring='accuracy', cv = 10)#refit com cabin
rna_refit_g2_search = GridSearchCV(estimator = mlp_g, param_grid = rna_param_grid,
                        refit=True, scoring='accuracy', cv = 10)#refit sem cabin

rna_g_search.fit(x_train_oversampled, y_train_oversampled);
print(f'\nMelhores Parâmetros: RNA com Cabin: ', rna_g_search.best_params_)
rna_g2_search.fit(x2_train_oversampled, y2_train_oversampled);
print(f'\nMelhores Parâmetros: RNA sem Cabin: ',rna_g2_search.best_params_)

print(f'\nMelhor Acurácia: RNA com Cabin: ', rna_g_search.best_score_)
print(f'\nMelhor Acurácia: RNA sem Cabin: ', rna_g2_search.best_score_)

tabelaAcc.loc[4, 'Redes Neurais 1 camada'] = rna_g_search.best_score_
tabelaAcc.loc[5, 'Redes Neurais 1 camada'] = rna_g2_search.best_score_

"""Conjunto Treino"""

rna_refit_g_search.fit(x_train_oversampled, y_train_oversampled);
rna_refit_g2_search.fit(x2_train_oversampled, y2_train_oversampled);

rna_train_g_results =  pd.DataFrame(rna_refit_g_search.cv_results_)
rna_train_g2_results =  pd.DataFrame(rna_refit_g2_search.cv_results_)

rna_train_g_results.loc[rna_refit_g_search.best_index_,'mean_test_score']

rna_train_g2_results.loc[rna_refit_g2_search.best_index_,'mean_test_score']

rna_train_g_search_model = rna_refit_g_search.best_estimator_
media_g_rna_treino = rna_train_g_search_model.score(x_train_oversampled,y_train_oversampled)
media_g_rna_treino

rna_train_g2_search_model = rna_refit_g2_search.best_estimator_
media_g2_rna_treino = rna_train_g2_search_model.score(x2_train_oversampled,y2_train_oversampled)
media_g2_rna_treino

tabelaTreino.loc[0, 'Redes Neurais 1'] = media_g_rna_treino
tabelaTreino.loc[0, 'Redes Neurais 2'] = media_g2_rna_treino

"""Média das Acurácias"""

rna_g_results =  pd.DataFrame(rna_g_search.cv_results_)
rna_g2_results = pd.DataFrame(rna_g2_search.cv_results_)

media_rna_g = rna_g_results.loc[rna_g_search.best_index_,'mean_test_score']

media_rna_g2 = rna_g2_results.loc[rna_g2_search.best_index_,'mean_test_score']

"""#### Randomized Search

#####Random Forest
"""

forest_r_search = RandomizedSearchCV(estimator = forest, param_distributions = forest_param_grid,
                        n_iter= 10, cv = 10, return_train_score=True)
forest_r2_search = RandomizedSearchCV(estimator = forest, param_distributions = forest_param_grid,
                        n_iter= 10, cv = 10, return_train_score=True)

forest_refit_r_search = RandomizedSearchCV(estimator = forest, param_distributions = forest_param_grid,
                        n_iter= 10, cv = 10, refit=True)
forest_refit_r2_search = RandomizedSearchCV(estimator = forest, param_distributions = forest_param_grid,
                        n_iter= 10, cv = 10, refit=True)

forest_r_search.fit(x_train_oversampled, y_train_oversampled); # com colunas de cabin
print(f'\nMelhores Parâmetros: Random Forest com Cabin: ', forest_r_search.best_params_)
forest_r2_search.fit(x2_train_oversampled, y2_train_oversampled); # sem colunas de cabin
print(f'\nMelhores Parâmetros: Random Forest sem Cabin: ', forest_r2_search.best_params_)

forest_r_search

print(f'\nMelhor Acurácia: Random Forest com Cabin: ', forest_r_search.best_score_)
print(f'\nMelhor Acurácia: Random Forest sem Cabin: ', forest_r2_search.best_score_)

tabelaAcc.loc[6, 'Random Forest'] = forest_r_search.best_score_
tabelaAcc.loc[7, 'Random Forest'] = forest_r2_search.best_score_

"""Conjunto Treino"""

forest_refit_r_search.fit(x_train_oversampled, y_train_oversampled);
forest_refit_r2_search.fit(x2_train_oversampled, y2_train_oversampled);

forest_train_r_results =  pd.DataFrame(forest_refit_r_search.cv_results_)
forest_train_r2_results =  pd.DataFrame(forest_refit_r2_search.cv_results_)

forest_train_r_results.loc[forest_refit_r_search.best_index_,'mean_test_score']

forest_train_r2_results.loc[forest_refit_r2_search.best_index_,'mean_test_score']

forest_train_r_model = forest_refit_r_search.best_estimator_
media_r_forest_train = forest_refit_r_search.score(x_train_oversampled,y_train_oversampled)
media_r_forest_train

forest_train_r2_model = forest_refit_r2_search.best_estimator_
media_r2_forest_train = forest_refit_r2_search.score(x2_train_oversampled,y2_train_oversampled)
media_r2_forest_train

tabelaTreino.loc[1, 'Random Forest 1'] = media_r_forest_train
tabelaTreino.loc[1, 'Random Forest 2'] = media_r2_forest_train

"""Média das Acurácias"""

forest_r_results =  pd.DataFrame(forest_r_search.cv_results_)
forest_r2_results = pd.DataFrame(forest_r2_search.cv_results_)

media_forest_r = forest_r_results.loc[forest_r_search.best_index_,'mean_test_score']
media_forest_r

media_forest_r2 = forest_r2_results.loc[forest_r2_search.best_index_,'mean_test_score']
media_forest_r2

"""#####Decision Tree"""

rtree_r_search = RandomizedSearchCV(estimator = decisionTree, param_distributions = decisionTree_param_grid,
                        n_iter= 10, cv = 10, return_train_score=True)
rtree_r2_search = RandomizedSearchCV(estimator = decisionTree, param_distributions = decisionTree_param_grid,
                        n_iter= 10, cv = 10, return_train_score=True)

rtree_refit_r_search = RandomizedSearchCV(estimator = decisionTree, param_distributions = decisionTree_param_grid,
                        n_iter= 10, cv = 10, refit=True)
rtree_refit_r2_search = RandomizedSearchCV(estimator = decisionTree, param_distributions = decisionTree_param_grid,
                        n_iter= 10, cv = 10, refit=True)

rtree_r_search.fit(x_train_oversampled, y_train_oversampled); # com colunas de cabin
print(f'\nMelhores Parâmetros: Decision Tree com Cabin: ', rtree_r_search.best_params_)
rtree_r2_search.fit(x2_train_oversampled, y2_train_oversampled); # sem colunas de cabin
print(f'\nMelhores Parâmetros: Decision Tree com Cabin: ', rtree_r2_search.best_params_)

print(f'\nMelhor Acurácia: Decision Tree com Cabin: ', rtree_r_search.best_score_)
print(f'\nMelhor Acurácia: Decision Tree sem Cabin: ', rtree_r2_search.best_score_)

tabelaAcc.loc[6, 'Decision Tree'] = rtree_r_search.best_score_
tabelaAcc.loc[7, 'Decision Tree'] = rtree_r2_search.best_score_

"""Conjunto Treino"""

rtree_refit_r_search.fit(x_train_oversampled, y_train_oversampled);
rtree_refit_r2_search.fit(x2_train_oversampled, y2_train_oversampled);

rtree_train_r_results =  pd.DataFrame(rtree_refit_r_search.cv_results_)
rtree_train_r2_results =  pd.DataFrame(rtree_refit_r2_search.cv_results_)

rtree_train_r_results.loc[rtree_refit_r_search.best_index_,'mean_test_score']

rtree_train_r2_results.loc[rtree_refit_r2_search.best_index_,'mean_test_score']

rtree_train_r_model = rtree_refit_r_search.best_estimator_
media_r_rtree_train = rtree_refit_r_search.score(x_train_oversampled,y_train_oversampled)
media_r_rtree_train

rtree_train_r2_model = rtree_refit_r2_search.best_estimator_
media_r2_rtree_train = rtree_refit_r2_search.score(x2_train_oversampled,y2_train_oversampled)
media_r2_rtree_train

tabelaTreino.loc[1, 'Decision Tree 1'] = media_r_rtree_train
tabelaTreino.loc[1, 'Decision Tree 2'] = media_r2_rtree_train

"""Média das Acurácias"""

rtree_r_results =  pd.DataFrame(rtree_r_search.cv_results_)
rtree_r2_results = pd.DataFrame(rtree_r2_search.cv_results_)

media_rtree_r = rtree_r_results.loc[rtree_r_search.best_index_,'mean_test_score']

media_rtree_r2 = rtree_r2_results.loc[rtree_r2_search.best_index_,'mean_test_score']

"""#####KNN"""

knn_r_search = RandomizedSearchCV(estimator = knn, param_distributions = knn_param_grid,
                        n_iter= 10, cv = 10, return_train_score=True)
knn_r2_search = RandomizedSearchCV(estimator = knn, param_distributions = knn_param_grid,
                        n_iter= 10, cv = 10, return_train_score=True)

knn_refit_r_search = RandomizedSearchCV(estimator = knn, param_distributions = knn_param_grid,
                        n_iter= 10, cv = 10, refit=True)
knn_refit_r2_search = RandomizedSearchCV(estimator = knn, param_distributions = knn_param_grid,
                        n_iter= 10, cv = 10, refit=True)

knn_r_search.fit(x_train_oversampled, y_train_oversampled); # com colunas de cabin
print(f'\nMelhores Parâmetros: KNN com Cabin: ', knn_r_search.best_params_)
knn_r2_search.fit(x2_train_oversampled, y2_train_oversampled); # sem colunas de cabin
print(f'\nMelhores Parâmetros: KNN com Cabin: ', knn_r2_search.best_params_)

print(f'\nMelhor Acurácia: KNN com Cabin: ', knn_r_search.best_score_)
print(f'\nMelhor Acurácia: KNN sem Cabin: ', knn_r2_search.best_score_)

tabelaAcc.loc[6, 'KNN'] = knn_r_search.best_score_
tabelaAcc.loc[7, 'KNN'] = knn_r2_search.best_score_

"""Conjunto Treino"""

knn_refit_r_search.fit(x_train_oversampled, y_train_oversampled);
knn_refit_r2_search.fit(x2_train_oversampled, y2_train_oversampled);

knn_train_r_results =  pd.DataFrame(knn_refit_r_search.cv_results_)
knn_train_r2_results =  pd.DataFrame(knn_refit_r2_search.cv_results_)

knn_train_r_results.loc[knn_refit_r_search.best_index_,'mean_test_score']

knn_train_r2_results.loc[knn_refit_r2_search.best_index_,'mean_test_score']

knn_train_r_model = knn_refit_r_search.best_estimator_
media_r_knn_train = knn_refit_r_search.score(x_train_oversampled,y_train_oversampled)
media_r_knn_train

knn_train_r2_model = knn_refit_r2_search.best_estimator_
media_r2_knn_train = knn_refit_r2_search.score(x2_train_oversampled,y2_train_oversampled)
media_r2_knn_train

tabelaTreino.loc[1, 'KNN 1'] = media_r_knn_train
tabelaTreino.loc[1, 'KNN 2'] = media_r2_knn_train

"""Média das Acurácias"""

knn_r_results =  pd.DataFrame(knn_r_search.cv_results_)
knn_r2_results = pd.DataFrame(knn_r2_search.cv_results_)

media_knn_r = knn_r_results.loc[knn_r_search.best_index_,'mean_test_score']

media_knn_r2 = knn_r2_results.loc[knn_r2_search.best_index_,'mean_test_score']

"""#####RNA SKLEARN"""

from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV

mlp = MLPClassifier(max_iter=2000)

rna_r_search = RandomizedSearchCV(estimator = mlp, param_distributions = rna_param_grid,
                        n_iter= 10, cv = 10, return_train_score=True)
rna_r2_search = RandomizedSearchCV(estimator = mlp, param_distributions = rna_param_grid,
                        n_iter= 10, cv = 10, return_train_score=True)

rna_refit_r_search = RandomizedSearchCV(estimator = mlp, param_distributions = rna_param_grid,
                        n_iter= 10, cv = 10, refit=True)
rna_refit_r2_search = RandomizedSearchCV(estimator = mlp, param_distributions = rna_param_grid,
                        n_iter= 10, cv = 10, refit=True)

rna_r_search.fit(x_train_oversampled, y_train_oversampled); # com colunas de cabin
print(f'\nMelhores Parâmetros: RNA com Cabin: ', rna_r_search.best_params_)
rna_r2_search.fit(x2_train_oversampled, y2_train_oversampled); # sem colunas de cabin
print(f'\nMelhores Parâmetros: RNA sem Cabin: ', rna_r2_search.best_params_)

print(f'\nMelhor Acurácia: RNA com Cabin: ', rna_r_search.best_score_)
print(f'\nMelhor Acurácia: RNA sem Cabin: ', rna_r2_search.best_score_)

tabelaAcc.loc[6, 'Redes Neurais 1 camada'] = rna_r_search.best_score_
tabelaAcc.loc[7, 'Redes Neurais 1 camada'] = rna_r2_search.best_score_

"""Conjunto Treino"""

rna_refit_r_search.fit(x_train_oversampled, y_train_oversampled);
rna_refit_r2_search.fit(x2_train_oversampled, y2_train_oversampled);

rna_train_r_results =  pd.DataFrame(rna_refit_r_search.cv_results_)
rna_train_r2_results =  pd.DataFrame(rna_refit_r2_search.cv_results_)

rna_train_r_results.loc[rna_refit_r_search.best_index_,'mean_test_score']

rna_train_r2_results.loc[rna_refit_r2_search.best_index_,'mean_test_score']

rna_train_r_model = rna_refit_r_search.best_estimator_
media_r_rna_train = rna_refit_r_search.score(x_train_oversampled,y_train_oversampled)
media_r_rna_train

rna_train_r2_model = rna_refit_r2_search.best_estimator_
media_r2_rna_train = rna_refit_r2_search.score(x2_train_oversampled,y2_train_oversampled)
media_r2_rna_train

tabelaTreino.loc[1, 'Redes Neurais 1'] = media_r_rna_train
tabelaTreino.loc[1, 'Redes Neurais 2'] = media_r2_rna_train

"""Média das Acurácias"""

rna_r_results =  pd.DataFrame(rna_r_search.cv_results_)
rna_r2_results = pd.DataFrame(rna_r2_search.cv_results_)

media_rna_r = rna_r_results.loc[rna_r_search.best_index_,'mean_test_score']

media_rna_r2 = rna_r2_results.loc[rna_r2_search.best_index_,'mean_test_score']

"""#Melhores Acurácias Finais"""

tabelaAcc

"""#Médias GridSearch e Randomized Search

###Preenchimento da Tabela de Médias
"""

tabelaMedias.loc[0, 'Random Forest 1'] = media_forest_g
tabelaMedias.loc[0, 'Random Forest 2'] = media_forest_g2
tabelaMedias.loc[0, 'Decision Tree 1'] = media_rtree_g
tabelaMedias.loc[0, 'Decision Tree 2'] = media_rtree_g2
tabelaMedias.loc[0, 'KNN 1'] = media_knn_g
tabelaMedias.loc[0, 'KNN 2'] = media_knn_g2
tabelaMedias.loc[0, 'Redes Neurais 1'] = media_rna_g
tabelaMedias.loc[0, 'Redes Neurais 2'] = media_rna_g2

tabelaMedias.loc[1, 'Random Forest 1'] = media_forest_r
tabelaMedias.loc[1, 'Random Forest 2'] = media_forest_r2
tabelaMedias.loc[1, 'Decision Tree 1'] = media_rtree_r
tabelaMedias.loc[1, 'Decision Tree 2'] = media_rtree_r2
tabelaMedias.loc[1, 'KNN 1'] = media_knn_r
tabelaMedias.loc[1, 'KNN 2'] = media_knn_r2
tabelaMedias.loc[1, 'Redes Neurais 1'] = media_rna_r
tabelaMedias.loc[1, 'Redes Neurais 2'] = media_rna_r2

"""#Médias Finais"""

tabelaMedias

"""#Avaliação do Conjunto Teste

####Random Forest
"""

forest_g_model = forest_g_search.best_estimator_
forest_g2_model = forest_g2_search.best_estimator_

forest_r_model = forest_r_search.best_estimator_
forest_r2_model = forest_r2_search.best_estimator_

forest_gc = forest_g_model.score(X_test,y_test)

forest_gc2 = forest_g2_model.score(X2_test,y2_test)

forest_rc = forest_r_model.score(X_test,y_test)

forest_rc2 = forest_r2_model.score(X2_test,y2_test)

tabelaTestes.loc[0, 'Random Forest 1'] = forest_gc
tabelaTestes.loc[0, 'Random Forest 2'] = forest_gc2
tabelaTestes.loc[1, 'Random Forest 1'] = forest_rc
tabelaTestes.loc[1, 'Random Forest 2'] = forest_rc2

"""####Decision Tree"""

rtree_g_model = rtree_g_search.best_estimator_
rtree_g2_model = rtree_g2_search.best_estimator_

rtree_r_model = rtree_r_search.best_estimator_
rtree_r2_model = rtree_r2_search.best_estimator_

rtree_gc = rtree_g_model.score(X_test,y_test)

rtree_gc2 = rtree_g2_model.score(X2_test,y2_test)

rtree_rc = rtree_r_model.score(X_test,y_test)

rtree_rc2 = rtree_r2_model.score(X2_test,y2_test)

tabelaTestes.loc[0, 'Decision Tree 1'] = rtree_gc
tabelaTestes.loc[0, 'Decision Tree 2'] = rtree_gc2
tabelaTestes.loc[1, 'Decision Tree 1'] = rtree_rc
tabelaTestes.loc[1, 'Decision Tree 2'] = rtree_rc2

"""####KNN"""

knn_g_model = knn_g_search.best_estimator_
knn_g2_model = knn_g2_search.best_estimator_

knn_r_model = knn_r_search.best_estimator_
knn_r2_model = knn_r2_search.best_estimator_

knn_gc = knn_g_model.score(X_test,y_test)

knn_gc2 = knn_g2_model.score(X2_test,y2_test)

knn_rc = knn_r_model.score(X_test,y_test)

knn_rc2 = knn_r2_model.score(X2_test,y2_test)

tabelaTestes.loc[0, 'KNN 1'] = knn_gc
tabelaTestes.loc[0, 'KNN 2'] = knn_gc2
tabelaTestes.loc[1, 'KNN 1'] = knn_rc
tabelaTestes.loc[1, 'KNN 2'] = knn_rc2

"""####Redes Neurais"""

rna_g_model = rna_g_search.best_estimator_
rna_g2_model = rna_g2_search.best_estimator_

rna_r_model = rna_r_search.best_estimator_
rna_r2_model = rna_r2_search.best_estimator_

rna_gc = rna_g_model.score(X_test,y_test)

rna_gc2 = rna_g2_model.score(X2_test,y2_test)

rna_rc = rna_r_model.score(X_test,y_test)

rna_rc2 = rna_r2_model.score(X2_test,y2_test)

tabelaTestes.loc[0, 'Redes Neurais 1'] = rna_gc
tabelaTestes.loc[0, 'Redes Neurais 2'] = rna_gc2
tabelaTestes.loc[1, 'Redes Neurais 1'] = rna_rc
tabelaTestes.loc[1, 'Redes Neurais 2'] = rna_rc2

"""#Média das Acurácias do Conjunto Teste"""

tabelaTestes

"""#Média das Acurácias do Conjunto Treino"""

tabelaTreino